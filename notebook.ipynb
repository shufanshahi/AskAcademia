{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8dfcd4-a55b-4105-bb2d-777a090284f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text : LangChain is a framework for developing applications powered by large language models (LLMs).  It's designed to make it easier to build LLM-powered applications by providing a structured way to:\n",
      "\n",
      "* **Chain together multiple calls to LLMs:**  Instead of just getting a single response from an LLM, LangChain allows you to create chains of calls, where the output of one call becomes the input to the next. This enables more complex and nuanced interactions with the LLM.\n",
      "\n",
      "* **Manage memory:**  LLMs are stateless, meaning they don't remember previous interactions. LangChain provides mechanisms for managing memory, allowing you to maintain context across multiple calls and build conversational agents.\n",
      "\n",
      "* **Connect to external data sources:**  LangChain enables you to connect LLMs to external data sources like databases, APIs, and files. This allows the LLM to access and process information beyond its initial training data.\n",
      "\n",
      "* **Modular components:**  LangChain is built with\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "llm = GooglePalm(\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],  # Pass your API key\n",
    "    model_name=\"gemini-1.5-flash\",  # Example model name\n",
    "    temperature=0.7,  # Adjust the temperature for creativity\n",
    "    max_output_tokens=200  # Limit the response token count\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b54a6ac-f865-4bd3-ac01-63f573a3bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column='prompt')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a997fa06-25ec-4e06-9031-6d2aca54015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MegaHard\\python3_12_4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: Default values for HuggingFaceBgeEmbeddings.model_name were deprecated in LangChain 0.2.5 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceBgeEmbeddings constructor instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "instructor_embeddings = HuggingFaceBgeEmbeddings()\n",
    "\n",
    "vectordb = FAISS.from_documents(documents=docs, embedding=instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c97207-f303-42f5-93e2-e1792d4fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1358cd1-77d4-4a1e-88e6-0bf83573886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9064\\1303278932.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rdocs = retriever.get_relevant_documents(\"for how long this course valid?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'What is the duration of this bootcamp? How long will it last?', 'row': 8}, page_content='prompt: What is the duration of this bootcamp? How long will it last?\\nresponse: You can complete all courses in 3 months if you dedicate 2-3 hours per day.'),\n",
       " Document(metadata={'source': 'Once purchased, is this course available for lifetime access?', 'row': 22}, page_content='prompt: Once purchased, is this course available for lifetime access?\\nresponse: Yes'),\n",
       " Document(metadata={'source': 'I’m not sure if this course is good enough for me to invest some money. What can I do?', 'row': 20}, page_content='prompt: I’m not sure if this course is good enough for me to invest some money. What can I do?\\nresponse: Don’t worry. Many videos in this course are free so watch them to get an idea of the quality of teaching. Dhaval Patel (the course instructor) runs a popular data science YouTube channel called Codebasics. On that, you can watch his videos and read comments to get an idea of his teaching style'),\n",
       " Document(metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5}, page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"for how long this course valid?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9106144-5ced-48e7-a299-2e216d617d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a888220-2a48-40c6-806c-3d62ee65fecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n",
      "\n",
      "Source Document: prompt: During the process of creating the line chart for forecast accuracy vs month in the Supply Chain View, I encountered an issue with the visual representation.\n",
      "The problem occurred at the 5:00-minute mark. I selected the year 2021, expecting the graph to display data only from September 2020 to August 2021.\n",
      "However, instead of the desired timeframe, the chart displayed data from all months between 2017 and 2022.\n",
      "\n",
      "How to solve and fix this issue?\n",
      "response: Check this reference:\n",
      "https://discordapp.com/channels/1090613684163850280/1113690341929918505/1113750218618445824\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\",prompt=PROMPT)\n",
    "\n",
    "\n",
    "retrieval_qa = RetrievalQA(\n",
    "    retriever=retriever,\n",
    "    combine_documents_chain=qa_chain,\n",
    "    input_key=\"query\",\n",
    ")\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "query = \"What is langchain?\"\n",
    "response = retrieval_qa.run({\"query\": query})\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(response)\n",
    "print(\"Source Document:\", relevant_documents[0].page_content)  # Output the content of the first document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
